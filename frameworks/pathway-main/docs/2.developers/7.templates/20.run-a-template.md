---
title: "Run a RAG template"
description: "How to run a RAG Pathway Template."
navigation: true
heading: false
toc: false
---

# Run a Pathway RAG Template

The Pathway RAG Templates provide ready-to-use setups for creating real-time, AI-driven applications.
With YAML-configured templates, it's easy to customize or create your own processing pipelines for use cases like RAG and ETL.

This quick start guide will help you set up and run Pathway Templates.
 Whether you're developing a document indexing solution, a knowledge mining system, or a query-response interface, this guide will get you started quickly.

## Prerequisites

To get started, you'll need:
- Git to clone the repository and manage updates
- LLM API Key (e.g., OpenAI or Hugging Face) for embedding and querying models

**Running Options**
1. Docker (recommended) will install all dependencies automatically
2. Python 3.8+ with [Pathway](/developers/user-guide/introduction/installation) if you prefer a local setup.

**Note**: if you are using Pathway locally, you will need to install Pathway LLM xpack with:

```
pip install pathway[all]
```

**Optional**: Install Streamlit for UI and pip for dependency management (if not using Docker).


## Clone the Repository

First, you need to download the repository.

```
git clone https://github.com/pathwaycom/llm-app.git
```


## Selecting Your Template

Pathway AI Pipelines provide several ready-to-go templates for common use cases.
Whether you need a real-time alerting system, document indexing, or context-based Q&A, you’ll find templates for each.
If none match your needs exactly, the framework provides all the necessary tools to [create your own pipeline](/developers/user-guide/llm-xpack/llm-app-pathway).

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/templates#llm"}
    See the templates.
    ::
::

Then you need to go the repository of the chosen template, let's take the `demo-question-answering` as an example.

```
cd llm-app/examples/pipelines/demo-question-answering
```

## Configuring and Running Pathway AI Pipelines

Most of the templates can be configured using a YAML file.
You can learn how to configure them by reading the [dedicated tutorial](/developers/templates/configure-yaml).

You can run Pathway AI Pipelines either locally or using Docker.
With Docker, setup is automated, handling all required dependencies.
For a local setup, you’ll install dependencies manually using Python and Pathway.
For detailed configuration and usage steps, refer to the README and articles included with each template.
